Class imbalance 클래스 불균형 

머신러닝 모델을 평가하는 하나의 지표로서 F1 score 고려
F1 score는 Precision - Recall 의 조화 평균으로부터 나오는 지표. 
주로 데이터 class(label)이 불균형 구조일 때 모델 성능을 정확히 평가 한다. 

데이터 불균형이란 어떤 데이터에서 각 클래스가 갖고 있는 데이터의 양에 차이가 큰 경우를 말한다. 

왜 클래스를 균형있게 만들어줘야 할까? 소수의 클래스의 의견에 귀를 기울이기 위해서다. 따라서 우리는 이러한 상황에서 

weight balancing 
train데이터에서 각 loss를 계산할 때 특정 클래스에 대해서는 더 큰 loss를 계산해주는 것이다.

이를 해결할 수 있는 방법 중 
오버 샘플링, 언더 샘플링 -> 데이터 수를 조정하는 방법-> 성능이 좋지 않음 

​

3) Weight balancing라고도 하며,Class 수가 2:8로 이루어져있다면, loss에 대해 Weight 가중치를 8:2로 설정하여 학습하는 방법이다.


Cost-sensitive learning이라고 하는 사람도 있고 정확한 용어로 정해져 있는지 확인해볼 필요가 있다.


케라스 프레임워크를 사용하면 model.fit 함수에 class_weight 항목을 참고하자.
[출처] Class imbalance(클래스 불균형) - 2) Solution|작성자 난니



비용민감 학습 
2.
Cost Sensitive Learning을 활용한 데이터 불균형 문제 해결하기

-> 데이터 자체를 생성하지 않지만. 머신러닝 학습할 때 소수의 클래스에 대한 cost값에 가중치를 더 많이 주어 균형 잡힌 학습이 가능하게 하는 방법 
  
필요한 라이브러리  import 
from numpy import mean, std
from sklearn.model_selection import RepeatedStratifiedKfold, cross_val_score

모델 생성 및 학습 
weights = {0:1.0, 1:10.0}


범주형 상관관계 
순위 상관 분석 - 켄달, 스피어만